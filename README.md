# textTokenizer
Program to tokenize the words in a text file and rank the most common relevant terms.

Instructions:
In order to run the code, you must download the following:
1. The latest version of Python
2. The matplotlib librabry for Python (Used to create the vocabulary and collection growth graph)

The program will take a any take file inputted by the user and tokenize its text. This means it will
remove all the words that are irrelevant to the text and transform the remaining words into most basic
stem word. From there, the program will extract the 200 most common terms from the tokenized text.
This process is similar to the one used by many search engines to extract the most relevant terms
from a file.
